{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20182ac7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01margparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Namespace\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdistributed\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mdistributed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdestroy_process_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/distributed/distributed_c10d.py:775\u001b[0m, in \u001b[0;36mdestroy_process_group\u001b[0;34m(group)\u001b[0m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m     pg \u001b[38;5;241m=\u001b[39m group\n\u001b[0;32m--> 775\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m pg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _pg_map\u001b[38;5;241m.\u001b[39mget(pg, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid process group specified\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <generator object tqdm.__iter__ at 0x7f1845e72200>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tqdm/std.py\", line 1181, in __iter__\r\n",
      "    yield obj\r\n",
      "KeyboardInterrupt: \r\n",
      "\r",
      "  0% 0/90000 [10:47<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "import torch.multiprocessing as mp\n",
    "from infer import infer\n",
    "from argparse import Namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9bae62d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: wjeliot (use `wandb login --relogin` to force relogin)\n",
      "wandb: Currently logged in as: wjeliot (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=32, depth=8, device='cuda', dropout=0.05, embedding_dim=256, final=False, forward_expansion=4, gradient_clipping=1, lr=0.001, lr_warmup=5000, mask=True, num_batches=90000, num_heads=8, sample_length=600, seed=-1, seq_len=50, test_every=200, test_size=25, vocab_len=52015)\n",
      "Namespace(batch_size=32, depth=8, device='cuda', dropout=0.05, embedding_dim=256, final=False, forward_expansion=4, gradient_clipping=1, lr=0.001, lr_warmup=5000, mask=True, num_batches=90000, num_heads=8, sample_length=600, seed=-1, seq_len=50, test_every=200, test_size=25, vocab_len=52015)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Tracking run with wandb version 0.12.9\n",
      "wandb: Syncing run colorful-silence-29\n",
      "wandb:  View project at https://wandb.ai/wjeliot/gpt_k\n",
      "wandb:  View run at https://wandb.ai/wjeliot/gpt_k/runs/28ng0p6c\n",
      "wandb: Run data is saved locally in /pipeline/notebook/gpt-k/wandb/run-20220127_113211-28ng0p6c\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Tracking run with wandb version 0.12.9\n",
      "wandb: Syncing run silver-snowflake-30\n",
      "wandb:  View project at https://wandb.ai/wjeliot/gpt_k\n",
      "wandb:  View run at https://wandb.ai/wjeliot/gpt_k/runs/3czvsduu\n",
      "wandb: Run data is saved locally in /pipeline/notebook/gpt-k/wandb/run-20220127_113211-3czvsduu\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "  0% 0/90000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Number of parameters:\r\n",
      "32,995,631\r\n",
      "\r\n",
      "Number of parameters:\r\n",
      "32,995,631\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Process SpawnProcess-2:\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py\", line 59, in _wrap\r\n",
      "    fn(i, *args)\r\n",
      "  File \"/pipeline/notebook/gpt-k/infer.py\", line 131, in infer\r\n",
      "    wandb.log({\"loss\": loss})\r\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 2532, in nll_loss\r\n",
      "    return torch._C._nn.nll_loss_nd(input, target, weight, _Reduction.get_enum(reduction), ignore_index)\r\n",
      "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:0! (when checking argument for argument target in method wrapper__nll_loss2d_forward)\r\n",
      "\r\n",
      "During handling of the above exception, another exception occurred:\r\n",
      "\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\r\n",
      "    self.run()\r\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\r\n",
      "    self._target(*self._args, **self._kwargs)\r\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py\", line 66, in _wrap\r\n",
      "    sys.exit(1)\r\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/wandb/sdk/lib/exit_hooks.py\", line 38, in exit\r\n",
      "    self._orig_exit(orig_code)\r\n",
      "SystemExit: 1\r\n",
      "\r\n",
      "During handling of the above exception, another exception occurred:\r\n",
      "\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 318, in _bootstrap\r\n",
      "    util._exit_function()\r\n",
      "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 357, in _exit_function\r\n",
      "    p.join()\r\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 149, in join\r\n",
      "    res = self._popen.wait(timeout)\r\n",
      "  File \"/usr/lib/python3.8/multiprocessing/popen_fork.py\", line 47, in wait\r\n",
      "    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\r\n",
      "  File \"/usr/lib/python3.8/multiprocessing/popen_fork.py\", line 27, in poll\r\n",
      "    pid, sts = os.waitpid(self.pid, flag)\r\n",
      "KeyboardInterrupt\r\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m params \u001b[38;5;241m=\u001b[39m Namespace(\n\u001b[1;32m     22\u001b[0m     num_batches\u001b[38;5;241m=\u001b[39mnum_batches,\n\u001b[1;32m     23\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     40\u001b[0m     test_size \u001b[38;5;241m=\u001b[39m test_size\n\u001b[1;32m     41\u001b[0m )\n\u001b[1;32m     43\u001b[0m world_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m---> 45\u001b[0m \u001b[43mmp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspawn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minfer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnprocs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworld_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py:230\u001b[0m, in \u001b[0;36mspawn\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    226\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis method only supports start_method=spawn (got: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    227\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTo use a different start_method use:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    228\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m torch.multiprocessing.start_processes(...)\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m start_method)\n\u001b[1;32m    229\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(msg)\n\u001b[0;32m--> 230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstart_processes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnprocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdaemon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mspawn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py:188\u001b[0m, in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    187\u001b[0m \u001b[38;5;66;03m# Loop on join until it returns True or raises an exception.\u001b[39;00m\n\u001b[0;32m--> 188\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py:99\u001b[0m, in \u001b[0;36mProcessContext.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# Wait for any process to fail or all of them to succeed.\u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m ready \u001b[38;5;241m=\u001b[39m \u001b[43mmultiprocessing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msentinels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m error_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentinel \u001b[38;5;129;01min\u001b[39;00m ready:\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m/usr/lib/python3.8/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_batches = 90000\n",
    "batch_size = 32\n",
    "embedding_dim = 256\n",
    "num_heads = 8\n",
    "mask = True\n",
    "dropout = 0.05\n",
    "forward_expansion = 4\n",
    "depth = 8\n",
    "seq_len = 50\n",
    "vocab_len = 52015\n",
    "device = \"cuda\"\n",
    "seed = -1\n",
    "lr = 0.001\n",
    "final = False\n",
    "test_every = 200\n",
    "gradient_clipping = 1\n",
    "lr_warmup = 5000\n",
    "sample_length = 600\n",
    "test_size = 25\n",
    "\n",
    "params = Namespace(\n",
    "    num_batches=num_batches,\n",
    "    batch_size=batch_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    num_heads=num_heads,\n",
    "    mask=mask,\n",
    "    dropout=dropout,\n",
    "    forward_expansion=forward_expansion,\n",
    "    depth=depth,\n",
    "    seq_len=seq_len,\n",
    "    vocab_len=vocab_len,\n",
    "    device=device,\n",
    "    seed=seed,\n",
    "    lr=lr,\n",
    "    final=final,\n",
    "    test_every=test_every,\n",
    "    gradient_clipping=gradient_clipping,\n",
    "    lr_warmup=lr_warmup,\n",
    "    sample_length=sample_length,\n",
    "    test_size = test_size\n",
    ")\n",
    "\n",
    "world_size = 2\n",
    "\n",
    "mp.spawn(infer, args=(world_size, params), nprocs=world_size, join=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "684px",
    "left": "1435px",
    "right": "20px",
    "top": "123px",
    "width": "272px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
